Nov 28 2014

We are building a sliding window filter for processing realtime data coming from a machine. Data
comes from many commanders and sensors. All data is related to each other using multiple models all
of which have parameters. Filter helps in updating the states of the machine, states of the models
(sensor models, kinematic-dynamic models etc.) and others. 

Implementation uses threaded programming. Using ready-made functionality is preferred for example
use boost constructs, gflags, glog etc.

Filter design will be made to be general enough so that same design can be used to filter data for
many different type of filter designs.

Filter performs the following steps:
  
  // Init
  
  Start with the knowledge of 
    different models that are to be included - it should be possible to exlude a model during runtime
    initializing period length - this much data will be used to initialize the models
    time interval after which older states should be marked to be marginalized - this may be changed at runtime
    
  Initialize
    check if all model objects are created, if not, either create or return with an error
    initiate the timers
      one timer for each model function call
      ekf steps timers
    initiate each model - this should create priors for each model
    
  Initiate models  
    fetch the amount of data indicated by initialization period length
    call each model's initializer with starting data to initiate each model
      this would typically use a convex optimization 
  
  // Get new data
    
  Fetch new data 
    since last data fetch timestamp
    readings associated with the given model set
  
  // Marginalize
  
  Mark states to be marginalized
    using its settings filter will mark certain states that are to be marginalized
    then it calls each model's marginalizer function to help mark which states are to be marginalized.
  
  Calculate marginals 
    use each model's logic to marginalize the model's states - this would need past estimates of the states
    use filter's logic to marginalize the states
  
  Remove states to be marginalized
    call each model's state remover function
    call filter's state remover
  
  // Process new data
  
  Create new states
    call each function's new state creator to add states to the filter
  
  Create new constraints
    call each function's constraints creater with relevant new readings to add constraints to the filter
  
  Filter outliers
    call each model's filtering step to remove any outliers
  
  // Solve the linear system 
  
  Solve the linear system
    use constraints to generate the linear system of equations
    solve the system - limit by the number of iterations and accuracy 
    
  Check for convergence
    check if the solving converged if not, 
      indicate by messaging 
      may be call each model's initializer again
      may be extend the window length
    
  // Save states
  
  Save states 
    save the current estimate of the states for future marginalization
  
  // Communicate for visualization
  
  Filter should be able to output its states
    plot of covariance/information matrices
    states for each model
    number of variables in all states
    number of constraints being generated by every model
    times taken in every step being performed
      new data fetch time
      marginalizing times for every model
      new states creation time for each model
      solving time 
    check if there are any updates to running parameters
  
  // Loop back
  
  Go back 
    if convergence was achieved, go back to fetch new data
    if not converged go back to initiate filter
  

Models create states and constraints using the data. Models may/maynot need sensor data to create states and constraints.
They implement the logic to calculate marginals for all existing states in the filter. Usually the filter decides which 
states are to be marginalized. But in case of specialized models such as Hybrid-MSCKF-EKFSLAM filter, model can decide which
older states are to be marginalized. Some examples of models follow

Tags Map
A tag-detector sensor detects the tags in the realtime images. These are queued up in the sensor queue. Filter picks these up
as they appear in the queue. When a new tag appears, a new tag-pose-state is initiated by the model. Lets say if there are 
multiple sub-maps of tags. Then, when a sub-map change is detected, the model can remove all tags in the current map and start
building a new map. If the poses of tags are known already (tags belong to a pre-mapped area) map-model would refine only the 
poses of the machine, using the relative poses of tags as fixed knowns.

Multi-state Constrained Kalman Filter
Another example of a model is a MSCKF from Mourikis et al. Here a rolling list of past states of images is kept till there is
any visual feature being tracked. Oldest states are then marginalized when no features that appear in them are being tracked. 
A MSCKF-model will keep the older states or convert them into feature tracks thus creating/deleting states as needed. It 
has to calculate the marginalization information accordingly. (I still need to undestand how marginalization works).

Keyframe-SLAM (multiple)
Many SLAM algorithms update information from each frame relative to a keyframe. The environment map is built as a sequence
of keyframes. Keyframes relate to each other using SE3 or Sim3 transforms jointly with the locations of 3d points. This is 
similar to the MSCKF setup. The realtime tracking thread of each SLAM algorithm can be run with SWF in realtime. Mapping 
threads of SLAM algorithms like LSD-SLAM could then be combined onto one filter. 

Ground model
Ground model would use some combination of u-v-disparity type approach combined with reconstructed 3d points. Whatever model
is used, a sliding filter based implementation that takes in delayed 3d-point information along with more current information
will be used. The future estimates of ground could then be included in sliding window to check if consecutive experience of
ground slope matches the expectations.

Beacon tracking
Similar to above beacon tracking is also a sliding window, multiple sensor optimization problem.


From the above filter design, each model is doing the following things:

  Set settings for the model

  Loads a prior from previous experience
  
  Processes starting data to initialize its states (maybe using some convex optimization)
  
  Mark states to be marginalized
  
  Calculate Marginals - this needs knowledge of other models in the filter
  
  Create new states
  
  Create constraints
  
  Outlier gating - this test would allow a model to decide if a constraint is not to be added
  
  Check convergence (?) needed
  
  Model state communication struct
  

  
Jan 2 2015

Filter design is taking sometime. Different Models could have their own sliding window sizes. E.g.

Visual part of the Hybrid-MSCKF can keep a variable number of last keyframes. The algorithm chooses
how many features are to be kept as states and which ones are to be marginalized out. Window size
is changed as needed based on some heuristics.

Kinematic model will keep its own states in time. Past states could be modified by newer readings,
but might change very little. Model might decide to marginalize those based on high certainty
estimated.

Then, what exactly is sliding window size? Sliding window size depends in the model. If a past
state of a model is still there, but all observations that had some input on them have been
marginalized, we will only have priors setup for those states. In that case solver will simply
use those priors. It appears that we can keep different filters' sliding window slightly different
as per model's needs as long as marginalization process is smart enough to handle loss of states
and observations. When observations are marginalized, models need to know so that they can
calculate priors to be imposed (if any) on their states.

Filter keeps track of the observations. It decides which observations are to be removed from the
ObservationsTracker.

Filter's solver will solve at the end of each iteration. The location of states where it will
solve will be allocated by the models. This will be a map of vectors of states. Map size is just
the number of models. Each vector has a size = number of states * number of elements in one state. 
As allocation/deallocation is expensive, we will preallocate the maps. This requires that Models
know their state sizes and maximum number of states to be allocated.

In addition Filter needs to know how many maps it needs to keep in memory that can be recycled.
Older state estimates are needed for chosing 'first estimate' linearization points for jacobian
calculations. Say each iteration of filter takes t_iteration time. Observations are being tracked
for t_obervations time. Then the n_states_history = t_obervations / t_iteration. In line with using
first estimates, we can use the rule that we keep observations in the filter to be included in
solving going back for a time interval of n_states_history * iteration_time. We can not expect to
have a fixed iteration_time. So we only specify a target_sliding_window. Based on the time it takes
to do an iteration, Filter will decide to marginalize all observations before the time of iteration
that happenned more than target_sliding_window in the past.

Jan 3 2015

Keeping observations in the filter

When new observations come in they are saved in a data structure, these are accessed by the Models
to create/constrain their states. Is there any need to use older observations? This does not seem
to be so. All current observations will lead to some type of state/constraint creation. In the
next iteration only new observations are needed as we are keeping old states in the StatesTracker.
Of course Models are using older observations, but these are via the states created in previous
iterations rather than reusing the older observations.

This means that it is necessary have a way to say 'these are the latest observations'. So the
data structure for observations is per iteration, setup as a map of protobuf messages.
  std::map< std::string, std::unique_ptr<std::vector<std::unique_ptr<google:protobuf::Message>>>>
A set of these maps are kept and reused. Number of maps kept could be limited by the number of
iterations per filter sliding window.

At startup, filter should know what types of messages it expects to get. When it gets the messages
it will enter them into the observations keeper. Observations are kept in a vector of above maps.
At startup filter should also get how many set of iterations it should keep. If you never need
older observations this number could be set to 1. But we should provide the ability to modify this
in time.

This pattern of circular pointer queue keeps coming up. It does the following:
  It is a template of a type of object it will keep
  Gets a MaxSize that defines the space it reserves at startup
  Gets a circular queue size
  Keeps indexes of current element and oldest element
  Both size and maxsize can be modified at run time
  All data is kept in the heap
  It can provide a const reference to the current element
  Its counter can be incremented
  May be it can provide the space occupied by the queue elements, not sure how
  
Jan 5 2015

Data loading is working fine in the filter now. Performance trackers and circular pointer queues
are now working. Time to resume building the models.

Models need to have an idea of the number of states they will create per iteration. States
tracker will keep a circular queue of maps to vectors that hold the states. States can simply be
defined as a vector of doubles for most purposes. There will be cases where is it not always true.
E.g. A model that is just trying to decide if the machine is indoors or outdoors could have a
state that is an enumeration {kIndoors, kOutdoors}. In this case it seems better to define a state
as a struct. But then we are not going to use that in optimization with ceres. Models with such
states could only be included in RandomForests style solvers.

This means that a state could have multiple 'representations'. A state could be seen as a struct
but it could also be seen as a vector<double> + set<classes> that can be solved in place. If we
design probit/logit type models, we would solve a binary variable with a continuum [0,1]. Usually
when we will solve for a model with classes, we would solve for probability(of this class). So if
we have an enum with 5 classes, its state representation will be a vector<double>.size=5, where
the values can vary in the interval [0,1]. 

Say, we are picking and placing pots in a yard. States are something like {kApproachingPot,
kCloseToPot, kPickingPot, kPickedUpPot, ... etc.} Such a state machine will need to know with
some certainty what the current state is. A Filter can be used to calculate the probabilities of
being in a certain state at a time. When picking up a pot, kPickedUpPot will depend on measurements
such as (1) pot location, (2) weight on the machine, (3) tension in pickup strings etc.

Say we are going from one place to another delivering things. A state machine could have states
{kAtStartingWaitingForLoad, kGotLoad, kTravellingToDestination, kReachedDestination, ... etc.}
Here the navigation filter's states will be inputs to the probabilities of each state. Plus some
other inputs like user's inputs can help determine the state probabilities. kGotLoad could have
input from the dynamics engine's mass estimate if there are no load sensors.

What if the number of states is variable? No issues, just a new state is added by the model to
its states. The model maintains the states. 

Bottomline is that for the target of solving in a sliding window filter, we can assume that states
are a vector<double> or vector<float>.

Jan 6 2015

Models do a number of activities. They know (a) the number of states they will have per sliding
window using their settings. At initiation Filter will create a StatesTracker which is a map of
vectors of states. Filter will pass a reference to the StatesTracker to the models and ask them to
(1) Allocate memory for their states. Models will allocate memory for their states that they will
reuse in a circular queue fashion.

Each iteration is identified with a timestamp that was the end-timestamp used to fetch the data for
that iteration. At the beginning of each iteration Filter gets the observations and provides to
each model for (2) state creation. Models then create new states using the observations and end
timestamp of iteration.

Once all models have created their states Filter will instantiate the Problem that is to be solved.
This object is then shipped to each model to add constraints. Constraints are residual objects. Past
states need to be marginalized. Marginals look like constraints on current states. These would use
a past estimate for linearization point for jacobian calculation. Marginals form a prior for some
states in the problem.

At this point I can not think of how the constraint creation with marginalization will work. In any
Problem solving we will have the prior, either through loading from disk (previous experience) or
through marginalization. New observations will cause new constraints to be created with the states.
There would also be some state-state constraints but I an not sure how those will work. Constraints
could be special objects that are used later by the ceres solver to create its residuals, or we
could tightly couple the solver by directly creating constraints in form of residuals. Whatever way
is chosen, at the end, we will have the state estimates in the state-vectors. With these we need to
get ready for the next iteration.

Once we have this iteration's state estimates, Filter asks every model to (3) save the estimates to
the states. After this, Filter communicates the calculations. It may be required that Filter serves
as a sensor of models' states and publishes out the latest estimates to a data queue. Models can
provide an interface to publish their results as a protobuf message. This would include the states
and their uncertainties. This might also include the times taken for calculations. Filter will then
call (4) Models' results communcation function to get the results in transmittable format. If a
setting of (b) transmit Model's state is set, then Filter will (5) transmit the message using its
publisher. Filter will do end-of-iteration house keeping such as setting various iteration timings
in its variables. These will be used by the Filter's AssembleStateString function that is sent to
the ProgramCommander.

So from the above design following settings and methods come out:

(0) Model::Initiate(ObservationsKeeper*, StatesTracker*) - when constructring the models 
(1) Model::AllocateMemoryForStates() - called after models have been created
(2) Model::CreateStates() - called at the beginning of each iteration
    ... marginalization, outlier gating, constraint creation methods ...
    ... Models know which states are being solved ...
    Filter::SolveProblem()
(3) Model::SaveEstimatesToStates() - states have the current estimates so save these
(4) Model::GetResultsAsMessage() - returns a Protobuf message ready to be transmitted
(5) Filter::TransmitResults() - if in filter settings say so, transmit the results message

Jan 7 2015

State design where each state keeps a circular queue is not a good idea. Everytime we have to
choose a linearization point, we will search for the past estimate in all states. This is not
efficient. A better design is as follows.

An EstimatesTracker will preallocate memory for the maximum number of states per model. This will
be a vector of maps of vectors of states. State here are just arrays. Each model knows which index
of states array is for which state. I wonder if it could just be a large vector allocated using
Eigen library. In that way it could be SSE aligned and thus ready for vector operations.

Jan 8 2015

EstimatesTracker keeps all estimates. Along with each estimates vector, it has space for state_id
of the states that have those estimates, plus the number of state estimates stored there. Number of
estimates is necessary to keep as the size of the estimates vector is the maximum needed size to
save from unnecessary allocation/deallocation of memory.

StatesTracker owns the states. A state is an id e.g. in kinematic model, a state is identified by
its timestamp. In visual odometry model state_id could be the feature_id, or a camera_frame's
timestamp. For a mapping model, it could be feature/object_id. etc.

StatesTracker also owns the state markings. A state's lifecycle is {kToBeCreated, kCreated,
kToBeEstimated, kEstimated, kToBeMarginalized, kMarginalized, kToBeDeleted, kDeleted}. A state
could be estimated a number of times while remains in the sliding window. So each state has a
counter num_estimates that keeps track of number of times it has been estimated. One more thing
could be to keep a vector with each state keeping the iteration_id's of the iterations the state
was estimated in, so everytime we estimate, we increment num_estimates and store iteration_id's.

After an iteration's Problem has beed solved, estimates are written in the EstimatesTracker. Model
will then do a post solving analysis. It can check if states that were reestimated had a reduction
in their uncertainty, did the solver converge, etc.

  -- Startup --
    Filter::CreateIterationTracker()
    Filter::CreateObservationsTracker()
    Filter::CreateStatesTracker()
    Filter::CreateEstimatesTracker()
    Filter::CreateModels()
(0) Model::Initiate(ObservationsKeeper*, StatesTracker*) - when constructring the models 
(1) Model::AllocateMemoryForStates() - called after models have been created
    Model::AllocateMemoryForEstimates() - allocates memory for estimates for every iteration
  -- Iteration --
(2) Model::CreateStates() - called at the beginning of each iteration
    Model::MarkStates() - mark states included in this iteration and ones to be marginalized
    Model::InitiateEstimates() - setup states in EstimatesTracker - state_ids's and starting values
    ... marginalization, outlier gating, constraint creation ...
    ... Models know which states are being solved ...
(3) Filter::SolveProblem() - 
    ... estimates are written in the EstimateTracker ...
    Model::ProcessEstimates() - Update states, do other processing with estimates
(4) Model::GetResultsAsMessage() - returns a Protobuf message ready to be transmitted
(5) Filter::TransmitResults() - if filter settings say so, transmit the results message


Feb 2 2015

Just went through the maths involved in optimization. The realtime infrastructure built above is
great, but at this point I need to figure out how to get the maths going. It might be better to
implment the maths in a separate program first, and then include it in the real time system.

The 'batch' system will operate on a large number of states, typically much more than the realtime
system. But the calculations of jacobians etc. will still be the same. Realtime will do more e.g.
marginalization of older states will be done in realtime system, not in batch mode.





